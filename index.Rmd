---
title: "Comparing three groups"
author: "Jelle J. Goeman and Aldo Solari"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


Supplementary R code for reproducing the examples in the paper ``Comparing three groups''. 

## One-way ANOVA example

This example is taken from Dobson's (1983) book, Section 7. 

Genetically similar seeds are randomly assigned to be raised
either under standard conditions (**control**) or in two different nutritionally enriched environments (**treatment A** and **treatment B**). After a predetermined period all plants are harvested, dried and weighed. The results, expressed as dried weight in grams, for samples of $10$ plants from each group are given in following Table. 


```{r, echo=FALSE, results='asis'}
library(dobson)
library(tidyr)
plant.dried %>%
  pivot_wider(names_from = group, 
              values_from = weight,
              values_fn = list) %>%
  knitr::kable()
rm(list=ls())
```


We assume the linear model
$$Y_{u,i} = \mu_i + \varepsilon_{u,i}, \qquad i=1,2,3, \quad u=1,\ldots,10,$$
where $Y_{u,i}$ is the response (dried weight) for unit $u$ in group $i$ ($i=1$ for control, $i=2$ for treatment A and $i=3$ for treatment B), and $\varepsilon_{u,i} \stackrel{\mathrm{iid}}{\sim} N(0,\sigma^2)$. 
We are interested in testing the global null hypothesis that all three group means are equal, i.e. $H_{123}: \mu_1 = \mu_2=\mu_3$, and the three null hypotheses about pairwise comparisons between groups, i.e. $H_{12}: \mu_1=\mu_2$, $H_{13}: \mu_1=\mu_3$ and $H_{23}: \mu_2=\mu_3$.  


To get estimates $\hat{\mu}_1$, $\hat{\mu}_2$, $\hat{\mu}_3$ and $\hat{\sigma}^2$:

```{r}
library(dobson)
fit <- lm(weight ~ group -1, plant.dried)
fit$coefficients
summary(fit)$sigma^2
```

Partial $F$-test unadjusted $p$-values for $H_{12}$, $H_{13}$ and $H_{23}$:

```{r}
fit_12 <- lm(weight ~ I(group=="TreatmentB"), plant.dried)
p_12 <- anova(fit_12,fit)[2,"Pr(>F)"]
p_12
fit_13 <- lm(weight ~ I(group=="TreatmentA"), plant.dried)
p_13 <- anova(fit_13,fit)[2,"Pr(>F)"]
p_13
fit_23 <- lm(weight ~ I(group=="Control"), plant.dried)
p_23 <- anova(fit_23,fit)[2,"Pr(>F)"]
p_23
```

Tukey's HSD adjusted $p$-values for $H_{12}$, $H_{13}$ and $H_{23}$:

```{r}
p_tuk <- TukeyHSD(aov(weight ~ group, data = plant.dried))$group[,'p adj']
p_tuk
```

Dunnett adjusted $p$-values for $H_{12}$ and $H_{13}$

```{r}
library(DescTools)
p_dun <- DunnettTest(weight ~ factor(group), plant.dried, control="Control")$Control[,'pval']
p_dun
```


ANOVA F-test (method A), closed Tukey (method B), closed Dunnett (method C) and Gatekeeping (method D) $p$-values for $H_{123}$:

```{r}
fit_123 <- lm(weight ~ 1, plant.dried)
p_A = anova(fit_123,fit)[2,"Pr(>F)"]
p_A
p_B = min(p_tuk)
p_B
p_C = min(p_dun)
p_C
p_D = p_12
p_D
```

Adjusted $p$-values for the four hypotheses and the four methods:

```{r}
adjp = matrix(NA,nrow=4,ncol=4,
              dimnames = list(c("A", "B", "C", "D"),
                               c("H12", "H13", "H23", "H123")))
adjp["A",] = pmax(c(p_12,p_13,p_23,p_A),p_A)
adjp["B",] = pmax(c(p_12,p_13,p_23,p_B),p_B)
adjp["C",] = pmax(c(p_12,p_13,p_23,p_C),p_C)
adjp["D",] = pmax(c(p_12,p_13,p_23,p_D),p_D)
adjp
```

We see that at the significance level of $\alpha=5\%$,
methods C and D do not reject
any hypothesis, while methods A and B reject $H_{123}$ and $H_{13}$.

For method A, add adjusted $p$-values to box-plots:

```{r, fig.width=5}
library(ggplot2)
library(ggpubr)
bp <- ggboxplot(plant.dried, x = "group", y = "weight")
stats <- compare_means(weight ~ group, data = plant.dried, method = "t.test")
stats$p.adj <- round(adjp["A",-4],3)
bp + stat_compare_means(method = "anova", label.y = 10) + 
  stat_pvalue_manual(stats, label = "p = {p.adj}", y.position =   c(9, 8, 7))
```

If we replace partial F-tests by two-samples $t$ tests, we obtain

```{r}
p_12 = stats$p[1]
p_13 = stats$p[2]
p_23 = stats$p[3]
adjp["A",] = pmax(c(p_12,p_13,p_23,p_A),p_A)
adjp["B",] = pmax(c(p_12,p_13,p_23,p_B),p_B)
adjp["C",] = pmax(c(p_12,p_13,p_23,p_C),p_C)
adjp["D",] = pmax(c(p_12,p_13,p_23,p_D),p_D)
adjp
```

resulting in the rejection of $H_{123}$, $H_{13}$ and $H_{23}$ at $\alpha=5\%$ for methods A and B.

#### Non-parametric analysis

In the non-parametric setting, we are interested in testing the global null hypothesis that the distributions of the three groups are equal, i.e. $H_{123}: F_1=F_2=F_3$, and the three null hypotheses about pairwise comparisons of distributions, i.e. $H_{12}: F_1=F_2$, $H_{13}: F_1=F_3$ and $H_{23}: F_2=F_3$, where $F_{i}(y) = \mathrm{pr}(Y_i \leq y)$ is the cumulative distribution function for group $i$. We will restrict attention to the shift model $F_i(y) = F(y - \mu_i)$ for an arbitrary cumulative distribution function $F$, so we go back to the original formulation $H_{123}: \mu_1 = \mu_2=\mu_3$, $H_{12}: \mu_1=\mu_2$, $H_{13}: \mu_1=\mu_3$ and $H_{23}: \mu_2=\mu_3$.

Classic distribution-free permutation tests use non-standardized test statistics $T_{ij} = (\hat{\mu}_i - \hat{\mu}_j)^2$ for testing $H_{ij}$, and $T_{123} = T_{12}+T_{23}+ T_{13}$,  $\tilde{T} = \max(T_{12}, T_{13},T_{23})$ and $\tilde{T}_{1}=\max(T_{12}, T_{13})$ for testing $H_{123}$. The construction of the permutation null distribution for each test statistic proceeds as follows. The observations of the groups are pooled, and the test statistic is recalculated for every permutation of the group labels. 

Permutation tests of $H_{123}$ uses a global permutation distribution, constructed by permuting the observations of all three groups. 

```{r, message=F, warning=F, error=F, comment=NA, fig.show='hold'}
library(multtest)
labels <- factor(plant.dried$group, labels=0:2)
labels <- as.numeric(levels(labels))[labels]
B = 10^5
labels.perm <- mt.sample.label(labels, test="f", B=B)
c12 = ( (labels.perm + 2) %% 3 ) -1
c13 = labels.perm - 1
c23 = ( (labels.perm + 1) %% 3 ) -1
y = plant.dried$weight
n = 10
stats.perm <- rbind(
( y %*% t(c12) / n )^2,
( y %*% t(c13) / n )^2,
( y %*% t(c23) / n )^2
)
hist(colSums(stats.perm), main="", xlab=expression(T[123]))
hist(apply(stats.perm,2,max), main="", xlab=expression( tilde(T) ) )
```

The permutation $p$-value is calculated
as the proportion of permutations where the test statistic is greater than or equal to the value computed on the original data.

```{r}
p_A <- mean( colSums(stats.perm) >= sum(stats.perm[,1]) )
p_A
p_B <- mean( apply(stats.perm,2,max) >= max(stats.perm[,1]) )
p_B
p_C <- mean( apply(stats.perm[-3,],2,max) >= max(stats.perm[-3,1]) )
p_C
```

The permutation version of the ANOVA F-test can also be obtained by

```{r}
t_123 <- mt.sample.teststat(y, labels, B=B, test="f")
p_A <- mean( t_123 >= t_123[1] )
p_A
```

Permutation tests of $H_{ij}$ use a local permutation distribution, constructed by permuting the observations of groups $i$ and $j$. 

```{r}
t_12 <- (mt.sample.teststat(y[labels!=2],labels[labels!=2], B=0, test="t.equalvar") ) ^2
p_12 <- mean(t_12 >= t_12[1])
p_12
t_13 = (mt.sample.teststat(y[labels!=1],labels[labels!=1]=="2", B=0, test="t.equalvar") ) ^2
p_13 <- mean(t_13 >= t_13[1])
p_13
t_23 = (mt.sample.teststat(y[labels!=0],labels[labels!=0]=="2", B=0, test="t.equalvar") ) ^2
p_23 <- mean(t_23 >= t_23[1])
p_23
```
Adjusted $p$-values with permutation tests for the four hypotheses and the four methods:

```{r}
p_D <- p_12
adjp["A",] = pmax(c(p_12,p_13,p_23,p_A),p_A)
adjp["B",] = pmax(c(p_12,p_13,p_23,p_B),p_B)
adjp["C",] = pmax(c(p_12,p_13,p_23,p_C),p_C)
adjp["D",] = pmax(c(p_12,p_13,p_23,p_D),p_D)
adjp
```

Rank tests can be obtained as a special case of permutation tests by replacing the observations with their ranks.

```{r}
r = rank(y)
ranks.perm <- rbind(
( r %*% t(c12) / n )^2,
( r %*% t(c13) / n )^2,
( r %*% t(c23) / n )^2
)
p_A <- mean( colSums(ranks.perm) >= sum(ranks.perm[,1]) )
p_B <- mean( apply(ranks.perm,2,max) >= max(ranks.perm[,1]) )
p_C <- mean( apply(ranks.perm[-3,],2,max) >= max(ranks.perm[-3,1]) )
```

Kruskal-Wallis test can also be obtained by

```{r}
w_123 <- mt.sample.teststat(y, labels, B=B, test="f", nonpara = "y")
p_A <- mean( w_123 >= w_123[1] )
p_A
```

Wilcoxon-Mann-Whitney tests are obtained by

```{r}
w_12 <- (mt.sample.teststat(y[labels!=2],labels[labels!=2], B=0, test="wilcoxon"))^2
p_12 <- mean(w_12 >= w_12[1])
w_13 = (mt.sample.teststat(y[labels!=1],labels[labels!=1]=="2", B=0, test="wilcoxon"))^2
p_13 <- mean(w_13 >= w_13[1])
w_23 = (mt.sample.teststat(y[labels!=0],labels[labels!=0]=="2", B=0, test="wilcoxon"))^2
p_23 <- mean(w_23 >= w_23[1])
p_D <- p_12
```

Adjusted $p$-values with rank tests for the four hypotheses and the four methods:

```{r}
adjp["A",] = pmax(c(p_12,p_13,p_23,p_A),p_A)
adjp["B",] = pmax(c(p_12,p_13,p_23,p_B),p_B)
adjp["C",] = pmax(c(p_12,p_13,p_23,p_C),p_C)
adjp["D",] = pmax(c(p_12,p_13,p_23,p_D),p_D)
adjp
```



## ANCOVA example


